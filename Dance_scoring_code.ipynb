{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Reshape, Conv2D, MaxPooling2D, SimpleRNN\n",
    "\n",
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r\"C:\\Users\\vedan\\Downloads\\data\\data\"\n",
    "outputmodel = r\"C:\\Users\\vedan\\Downloads\\data\\video_classification_model\\videoclassificationmodel_\"\n",
    "\n",
    "# outputmodel = r\"C:\\Users\\vedan\\Downloads\\data\\video_classification_model\\videoclassificationmodel\"\n",
    "# outputlabelbinarizer = r\"C:\\Users\\vedan\\Downloads\\data\\model\\videoclassificationoinarizer\"\n",
    "epoch = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sports_labels = set([\"ClassicalDance\"])\n",
    "# print(\"images is being uploaded.....\")\n",
    "# pathToImages = list(paths.list_images(datapath))\n",
    "# data = []\n",
    "# labels = []\n",
    "\n",
    "# for images in pathToImages:\n",
    "#     label = images.split(os.path.sep)[-2]\n",
    "#     if label not in sports_labels:\n",
    "#         continue\n",
    "#     image = cv2.imread(images)\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#     image = cv2.resize(image, (224, 224))\n",
    "#     data.append(image)\n",
    "#     labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathToImages = list(paths.list_images(datapath))\n",
    "# for images in pathToImages:\n",
    "# #     print(images)\n",
    "#     label = images.split(os.path.sep)[-2]\n",
    "#     print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images is being uploaded.....\n",
      "bellet_full_data\n",
      "indianclassical\n",
      "dancehall\n",
      "hiphop\n",
      "house\n",
      "salsa\n",
      "jazz\n",
      "{'bellet_full_data': 0, 'indianclassical': 1, 'dancehall': 2, 'hiphop': 3, 'house': 4, 'salsa': 5, 'jazz': 6}\n",
      "afro\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "['dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'dancehall', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical', 'indianclassical']\n"
     ]
    }
   ],
   "source": [
    "sports_labels = set([\"indianclassical\", \"dancehall\"])\n",
    "# sports_labels = set([\"house\", \"salsa\", \"jazz\"])\n",
    "# sports_labels = set([\"ballet\", \"dancehall\"])\n",
    "labels_ = [\"bellet_full_data\", \"indianclassical\", \"dancehall\", \"hiphop\", \"house\", \"salsa\", \"jazz\"]\n",
    "labels_dict = {}\n",
    "labels_dict[\"indianclassical\"] = 1\n",
    "labels_dict[\"dancehall\"] = 0\n",
    "labels_dict[\"hiphop\"] = 0\n",
    "print(\"images is being uploaded.....\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "labels__ = []\n",
    "gen_label = {}\n",
    "\n",
    "for idx, label in enumerate(labels_):\n",
    "    print(label)\n",
    "    gen_label[label] = idx\n",
    "\n",
    "print(gen_label)\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    print(label)\n",
    "    break\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in sports_labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image/255.0\n",
    "    data.append(image)\n",
    "#     if \n",
    "    labels.append(label)\n",
    "    labels__.append(labels_dict[label]) \n",
    "\n",
    "print(labels__)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(638,)\n",
      "(638, 1)\n"
     ]
    }
   ],
   "source": [
    "# data = np.array(data)\n",
    "# labels = np.array(labels)\n",
    "# lb = LabelBinarizer()\n",
    "# labels = lb.fit_transform(labels)\n",
    "data = np.array(data)\n",
    "print(np.array(labels__).shape)\n",
    "labels__ = np.array(labels__)\n",
    "labels__ = labels__[..., np.newaxis]\n",
    "print(np.array(labels__).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data, labels__, test_size=0.25, stratify=labels, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(478, 224, 224, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Reshape((64, -1)))\n",
    "# model.add(Permute((2, 1)))\n",
    "model.add(SimpleRNN(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 64, 11881)         0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 128)               1537280   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,564,993\n",
      "Trainable params: 1,564,993\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(478, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "15/15 [==============================] - 15s 975ms/step - loss: 0.6292 - accuracy: 0.6234 - val_loss: 0.5011 - val_accuracy: 0.7375\n",
      "Epoch 2/2\n",
      "15/15 [==============================] - 14s 966ms/step - loss: 0.4106 - accuracy: 0.7950 - val_loss: 0.2795 - val_accuracy: 0.9187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a512d8d5b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=2, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91758096]\n"
     ]
    }
   ],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = [Y_pred]\n",
    "\n",
    "Y_pre = model.predict(np.expand_dims(X_test[0], axis=0))[0]\n",
    "print(Y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(X_test[0])\n",
    "cv2.imshow(\"image\", X_test[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-h4wtvo23\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7d2d9785625d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Our operations on the frame come here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# Display the resulting frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.4.0) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-h4wtvo23\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(\"test_scoring_video.mp4\")\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = [Y_pred]\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(298, 224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vedan\\Downloads\\data\\video_classification_model\\videoclassificationmodel_\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(outputmodel)\n",
    "lbinarizer = open(\"data_small_nn_workking.pickle\", \"wb\")\n",
    "with open('data_small_nn_workking.pickle', 'wb') as f:\n",
    "        pickle.dump(labels__, f)\n",
    "# lbinarizer.write(pickle.dump(lb))\n",
    "lbinarizer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "\n",
    "outputmodel = r\"C:\\Users\\vedan\\Downloads\\data\\video_classification_model\\videoclassificationmodel_\"\n",
    "\n",
    "model = load_model(outputmodel)\n",
    "with open('data_small_nn_workking.pickle', 'rb') as f:\n",
    "    lb = pickle.load(f)\n",
    "# mean = np.array([123.68, 110.779, 103.939][::1], dtype=\"float32\")\n",
    "Queue = deque(maxlen=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Queue = deque(maxlen=128)\n",
    "\n",
    "outputvideo = \"demo_output_.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing.....\n"
     ]
    }
   ],
   "source": [
    "capture_video = cv2.VideoCapture(\"test_scoring_video.mp4\")\n",
    "writer = None\n",
    "(Width, Height) = (None, None)\n",
    "\n",
    "while True:\n",
    "    (taken, frame) = capture_video.read()\n",
    "    if not taken:\n",
    "        break\n",
    "    if Width is None and Height is None:\n",
    "        (Width, Height) = frame.shape[:2]\n",
    "    \n",
    "    output = frame.copy()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (224, 224)).astype(\"float32\")\n",
    "#     print(frame.shape)\n",
    "#     frame = mean\n",
    "#     print(frame.shape)\n",
    "    preds = model.predict(np.expand_dims(frame/255.0, axis=0))[0]\n",
    "    Queue.append(preds)\n",
    "    results = np.array(Queue).mean(axis=0)\n",
    "    i = np.max(results)\n",
    "    score = preds*10\n",
    "#     preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "#     preds = model.predict(np.expand_dims(frame, axis=0))[0]\n",
    "#     Queue.append(preds)\n",
    "#     results = np.array(Queue)\n",
    "#     i = results\n",
    "#     label = i\n",
    "#     label = lb.classes_[i]\n",
    "    text = \"The score is : {:.2f}\".format(float(score))\n",
    "    cv2.putText(output, text, (45, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.25, (255,0,0), 5)\n",
    "    \n",
    "    if writer is None:\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "    writer = cv2.VideoWriter(\"outputvideo\", fourcc, 30, (Width, Height), True)\n",
    "    cv2.imshow(\"In progress\" ,output)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "print(\"Finalizing.....\")\n",
    "writer.release()\n",
    "capture_video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = []\n",
    "\n",
    "path, dirs, files = next(os.walk('C:/Users/vedan/Downloads/test_scoring_video_frames'))\n",
    "for file in files:\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = image/255.0\n",
    "    X_test_data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_data = np.array(X_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test_data)\n",
    "Y_pred = [Y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 610, 1)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
